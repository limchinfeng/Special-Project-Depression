{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925d1f45",
   "metadata": {},
   "source": [
    "### Stage 3 NDG <br>\n",
    "\n",
    "Check the metadata and english percentage of 100 users in NDG and DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb4ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "import pandas as pd\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from googletrans import Translator\n",
    "# DetectorFactory.seed = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d00f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text = \"@JadenMcDanielsF It is insanely bias but thatâ€™s not the real problem. Thereâ€™s just too many fouls in general. Itâ€™s actually getting unwatchable. The players are better than ever but the product keeps getting worse. The best players are supposed to be good because they CREATE SPACE.\"\n",
    "if (detect(text)==\"en\"):\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c515713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for NDG Metadata English Percentage_V4.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Stage 2 NonDepressionGroup_V4.csv\")\n",
    "twitterid = data.TwitterID\n",
    "attributes_container = []\n",
    "\n",
    "for index,id in enumerate(twitterid):\n",
    "    filename = \"V4/NDG_\" + str(index) + \"_\" + id +\".csv\"\n",
    "    \n",
    "    NDGUser = pd.read_csv(filename)\n",
    "#     print(filename)\n",
    "    \n",
    "    NDGUser['DateDepressionReported'] = pd.to_datetime(NDGUser['DateDepressionReported'], format='%d-%m-%Y')\n",
    "    \n",
    "    numTweet = len(NDGUser.ActualTweet)\n",
    "    minDate = NDGUser['DateDepressionReported'].min()\n",
    "    maxDate = NDGUser['DateDepressionReported'].max()\n",
    "\n",
    "    englishTweet = 0\n",
    "    # for tweets in NDGUser.TweetContent[58:59]:\n",
    "    #     print(tweets)\n",
    "    #     if(detect(tweets)==\"en\"):\n",
    "    #         englishTweet+=1\n",
    "    #     else:\n",
    "    #         print(detect(tweets))\n",
    "\n",
    "    for tweets in NDGUser.TweetContent:\n",
    "        try:\n",
    "            if(detect(tweets)==\"en\"):\n",
    "                englishTweet+=1\n",
    "        except:\n",
    "            englishTweet = englishTweet \n",
    "        \n",
    "    englishPercentage = englishTweet/numTweet\n",
    "    \n",
    "    attributes_container.append({\"ID\":index,\"TwitterID\":id,\"NumTweet\":numTweet, \"MinDate\":minDate, \"MaxDate\":maxDate, \"EnglishPercentage\":englishPercentage})\n",
    "\n",
    "                                 \n",
    "\n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"ID\",\"TwitterID\",\"NumTweet\", \"MinDate\", \"MaxDate\",\"EnglishPercentage\"])\n",
    "\n",
    "file_name = \"NDG Metadata English Percentage_V4.csv\"\n",
    "tweets_df.to_csv(file_name,index=False)\n",
    "print(\"Done for \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3b10ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for DG Metadata English Percentage_V3.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Depression Stage 2_V3.csv\")\n",
    "twitterid = data.TwitterID\n",
    "attributes_container = []\n",
    "\n",
    "for index,id in enumerate(twitterid):\n",
    "    filename = \"Stage 3/Depression Group/V3/DG_\" + str(index) + \"_\" + id +\".csv\"\n",
    "    \n",
    "    NDGUser = pd.read_csv(filename)\n",
    "#     print(filename)\n",
    "    \n",
    "    NDGUser['DateDepressionReported'] = pd.to_datetime(NDGUser['DateDepressionReported'], format='%d-%m-%Y')\n",
    "    \n",
    "    numTweet = len(NDGUser.ActualTweet)\n",
    "    minDate = NDGUser['DateDepressionReported'].min()\n",
    "    maxDate = NDGUser['DateDepressionReported'].max()\n",
    "\n",
    "    englishTweet = 0\n",
    "    # for tweets in NDGUser.TweetContent[58:59]:\n",
    "    #     print(tweets)\n",
    "    #     if(detect(tweets)==\"en\"):\n",
    "    #         englishTweet+=1\n",
    "    #     else:\n",
    "    #         print(detect(tweets))\n",
    "\n",
    "    for tweets in NDGUser.TweetContent:\n",
    "        try:\n",
    "            if(detect(tweets)==\"en\"):\n",
    "                englishTweet+=1\n",
    "        except:\n",
    "            englishTweet = englishTweet \n",
    "        \n",
    "    englishPercentage = englishTweet/numTweet\n",
    "    \n",
    "    attributes_container.append({\"ID\":index,\"TwitterID\":id,\"NumTweet\":numTweet, \"MinDate\":minDate, \"MaxDate\":maxDate, \"EnglishPercentage\":englishPercentage})\n",
    "\n",
    "                                 \n",
    "\n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"ID\",\"TwitterID\",\"NumTweet\", \"MinDate\", \"MaxDate\",\"EnglishPercentage\"])\n",
    "\n",
    "file_name = \"DG Metadata English Percentage_V3.csv\"\n",
    "tweets_df.to_csv(file_name,index=False)\n",
    "print(\"Done for \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31cce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for #NDG Metadata English Percentage for all Unchecked User.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"ALL/#Unchecked NDG.csv\")\n",
    "twitterid = data.TwitterID\n",
    "usergroup = data.Group\n",
    "attributes_container = []\n",
    "\n",
    "for index,id in enumerate(twitterid):\n",
    "    filename = \"ALL/NDG_\" + usergroup[index]  +\"_\"+ str(index+1)+ \"_\" + id +\".csv\"\n",
    "    NDGUser = pd.read_csv(filename)\n",
    "    \n",
    "    NDGUser['DateDepressionReported'] = pd.to_datetime(NDGUser['DateDepressionReported'], format='%d-%m-%Y')\n",
    "    \n",
    "    numTweet = len(NDGUser.ActualTweet)\n",
    "    minDate = NDGUser['DateDepressionReported'].min()\n",
    "    maxDate = NDGUser['DateDepressionReported'].max()\n",
    "\n",
    "    englishTweet = 0\n",
    "\n",
    "\n",
    "    for tweets in NDGUser.TweetContent:\n",
    "        try:\n",
    "            if(detect(tweets)==\"en\"):\n",
    "                englishTweet+=1\n",
    "        except:\n",
    "            englishTweet = englishTweet \n",
    "\n",
    "    if(numTweet == 0):\n",
    "          englishPercentage = 0\n",
    "    else:  \n",
    "        englishPercentage = englishTweet/numTweet\n",
    "    \n",
    "    attributes_container.append({\"ID\":index,\"TwitterID\":id,\"NumTweet\":numTweet, \"MinDate\":minDate, \"MaxDate\":maxDate, \"EnglishPercentage\":englishPercentage, \"Group\":usergroup[index]})\n",
    "\n",
    "                                 \n",
    "\n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"ID\",\"TwitterID\",\"NumTweet\", \"MinDate\", \"MaxDate\",\"EnglishPercentage\",\"Group\"])\n",
    "\n",
    "file_name = \"#NDG Metadata English Percentage for all Unchecked User.csv\"\n",
    "tweets_df.to_csv(file_name,index=False)\n",
    "print(\"Done for \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258a26c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for #NDG Metadata English Percentage_V5.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"V5/#Stage 2 NonDepressionGroup_V5.csv\")\n",
    "twitterid = data.TwitterID\n",
    "usergroup = data.Keyword\n",
    "attributes_container = []\n",
    "\n",
    "for index,id in enumerate(twitterid):\n",
    "    filename = \"V5/NDG_\" + str(index)+ \"_\" + id +\".csv\"\n",
    "    NDGUser = pd.read_csv(filename)\n",
    "    \n",
    "    NDGUser['DateDepressionReported'] = pd.to_datetime(NDGUser['DateDepressionReported'], format='%d-%m-%Y')\n",
    "    \n",
    "    numTweet = len(NDGUser.ActualTweet)\n",
    "    minDate = NDGUser['DateDepressionReported'].min()\n",
    "    maxDate = NDGUser['DateDepressionReported'].max()\n",
    "\n",
    "    englishTweet = 0\n",
    "\n",
    "\n",
    "    for tweets in NDGUser.TweetContent:\n",
    "        try:\n",
    "            if(detect(tweets)==\"en\"):\n",
    "                englishTweet+=1\n",
    "        except:\n",
    "            englishTweet = englishTweet \n",
    "\n",
    "    if(numTweet == 0):\n",
    "          englishPercentage = 0\n",
    "    else:  \n",
    "        englishPercentage = englishTweet/numTweet\n",
    "    \n",
    "    attributes_container.append({\"ID\":index,\"TwitterID\":id,\"NumTweet\":numTweet, \"MinDate\":minDate, \"MaxDate\":maxDate, \"EnglishPercentage\":englishPercentage, \"Group\":usergroup[index]})\n",
    "\n",
    "                                 \n",
    "\n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"ID\",\"TwitterID\",\"NumTweet\", \"MinDate\", \"MaxDate\",\"EnglishPercentage\",\"Group\"])\n",
    "\n",
    "file_name = \"#NDG Metadata English Percentage_V5.csv\"\n",
    "tweets_df.to_csv(file_name,index=False)\n",
    "print(\"Done for \" + file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
